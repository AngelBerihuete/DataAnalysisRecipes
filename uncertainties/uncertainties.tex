% This document is part of the Data Analysis Recipes project.
% Copyright 2020 the author.

% to-do
% -----
% - make up a toy data set and make problems.
%   - make two different generative models for the toy data.
%   - should have bayes and frequentist options.
% - get BibTeX working like GPR.
% - Where does the point go that there are many qualitatively different
%   sources of noise or uncertainty.
% - See notes from Stars & Exoplanets meeting 2020-06-03.
% - Make common style file for both this document and GaussianProductRefactor
% - Before submission: Check that all notes are displayed, and that they are on
%   the correct pages; marginfix is unstable.

\documentclass[10pt]{article}
\usepackage{amsmath, bm, mathrsfs, amssymb}
\usepackage[dvipsnames]{xcolor}
\usepackage[hidelinks,
            colorlinks=true,
            linkcolor=NavyBlue,
            citecolor=darkgray,
            urlcolor=NavyBlue]{hyperref}
\usepackage{graphicx}
\usepackage{marginfix} % necessary but possibly evil
% Note to the archaeologists who find this file: The marginfix package is unstable and buggy. It needs to be rewritten.

% citation stuhh
\usepackage{doi}
\usepackage{natbib}
\bibliographystyle{hogg_abbrvnat}
\setcitestyle{round,citesep={,},aysep={}}

% text macros
\newcommand{\foreign}[1]{\textsl{#1}}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\documentname}{\textsl{Note}}
\newcommand{\sectionname}{Section}
\newcommand{\equationname}{equation}

% math macros
\newcommand{\hquad}{~~}
\newcommand{\given}{\,|\,}
\newcommand{\dd}{\mathrm{d}}
\newcommand{\T}{^{\!\mathsf{T}\!}}
\newcommand{\inv}{^{-1}}
\newcommand{\scalar}[1]{#1}
\renewcommand{\vector}[1]{\boldsymbol{#1}}
\newcommand{\tensor}[1]{\mathbf{#1}}
\renewcommand{\matrix}[1]{\mathsf{#1}}
\newcommand{\normal}{\mathcal{N}\!\,}
\newcommand{\like}{\mathscr{L}}

% variables
\newcommand{\va}{\vector{a}}
\newcommand{\vy}{\vector{y}}
\newcommand{\tC}{\tensor{C}}
\newcommand{\mX}{\matrix{X}}

% page layout stuhh
\setlength{\headheight}{0.0in}
\setlength{\headsep}{0.0in}
\setlength{\parindent}{\baselineskip}
\setlength{\textwidth}{4.3in}
\setlength{\textheight}{2\textwidth}
\raggedbottom\sloppy\sloppypar\frenchspacing

% this might be crazy, but here's my number
\setlength{\marginparsep}{0.15in}
\setlength{\marginparwidth}{2.7in}
\newcounter{marginnote}
\setcounter{marginnote}{0}
\renewcommand{\footnote}[1]{\refstepcounter{marginnote}\textsuperscript{\themarginnote}\marginpar{\color{darkgray}\raggedright\footnotesize\textsuperscript{\themarginnote}#1}}
\newcommand{\tfigurerule}{\rule{0pt}{1ex}\\ \rule{\marginparwidth}{0.5pt}\\ \rule{0pt}{0.25ex}}
\newcommand{\bfigurerule}{\rule{0pt}{0.25ex}\\ \rule{\marginparwidth}{0.5pt}\\ \rule{0pt}{1ex}}
\renewcommand{\caption}[1]{\parbox{\marginparwidth}{\footnotesize\refstepcounter{figure}\textbf{\figurename~\thefigure}: {#1}}}

% and make the left margin correct
\setlength{\oddsidemargin}{0.5\paperwidth}
\addtolength{\oddsidemargin}{-1.0in}
\addtolength{\oddsidemargin}{-0.5\textwidth}
\addtolength{\oddsidemargin}{-0.5\marginparwidth}
\addtolength{\oddsidemargin}{-0.5\marginparsep}

% and the top margin
\setlength{\topmargin}{0.5\paperheight}
\addtolength{\topmargin}{-1.0in}
\addtolength{\topmargin}{-0.5\textheight}

\begin{document}\sloppy\sloppypar\raggedbottom\frenchspacing

\section*{Data Analysis Recipes: What is \\ the uncertainty on my measurement?}

\textbf{David W. Hogg}\footnote{%
    It is a pleasure to thank
    the participants in my data-analysis classes in New York City,
    and
    the weekly Stars and Exoplanets meeting at the Flatiron Insititute
    for help with all of this material.} \\
{\footnotesize Center for Cosmology and Particle Physics, Dept Physics, New York University} \\
{\footnotesize Max-Planck-Institut f\"ur Astronomie} \\
{\footnotesize Flatiron Institute}

\paragraph{Abstract:}
Any measurement you make using data ought to be reported with an uncertainty
estimate (often called an ``error'' or an ``error bar'' unfortunately).
I discuss and compare methodologies for making such estimates.
The options availble to you depend on whether you have a generative model for your
data, with which either you can simulate your noisy data, or (even better)
you can compute probability densities for different data sets.
They also depend on whether you believe that model,
or believe what it implies for the moments of the noise distribution.
If you have a good generative model, information theory or data simulations can deliver
measurement uncertainties; if you don't they can often provide strong bounds.
Either way, bootstrap and jackknife methods provide well justified, empirical
alternatives that I recommend.
I also discuss the role of nuisance parameters in uncertainty estimation, and
the differences between Bayesian and frequentist approaches and interpretation.
I spend a bit of time on common issues and troubleshooting.
One important idea is that the circumstances in which an uncertainty can be estimated
precisely are rare: Even when you have a very precise measurement, you probably won't
know the uncertainty on that measurement with great precision.

\section{Measurements and uncertainties}

You have data. There's something you want to measure. You have many
options for making this measurement: You can come up with an
\textsl{estimator}, that transforms your data (through arithmetic
operations) into an estimate of the quantity you want to measure. You
can write down a likelihood function---a probability density function
(or pdf) for your data given the quantity you want to measure (and
maybe other nuisance parameters)---and you can optimize it. That
procedure will get you an estimator, but it would be a
\textsl{maximum-likelihood estimator}, which has some great
properties (to be discussed below).
Or you can write down, in addition to your likelihood
function, a set of prior pdfs over parameters and perform
\textsl{Bayesian inference}.  In each of these cases you will make
some kind of measurement, and in each of these cases you will be
expected to deliver that measurement with an associated \textsl{uncertainty}.

This estimate of your uncertainty can come from different kinds of operations, with
different epistemological status. In some kinds of uncertainty
estimates, we use physical knowledge of the data-generating process to
compute, from (essentially) theory, how the noise in the data
contaminates the measurement. In other kinds of uncertainty estimates,
we use the variance or noise visible in the data to estimate the measurement
uncertainty. Loyal readers of \documentname s in this series can imagine that
I am generally partial to empirical or data-driven uncertainty estimates over
theoretical uncertainty estimates! But I discuss both in detail in what follows,
because (in the physical sciences at least) there are often cases in which the
theoretical uncertainties are very close to correct, or at least very useful.

And---closely related to the above point---the \emph{source} of the
uncertainty can be a well-defined noise process (like photon shot
noise in a detector); or it can be an ill-understood noise process
(like the variabilities of stars, for which we have no good model); or
it can be something else (unknown calibration systematics, mistakes or
wrong approximations in the physical model, and so on). For some analysses
all of these noise processes are relevant; for others only some are.
That is, the way uncertainties are estimated has something to do with
\emph{how they will be used}. This is related to the (sometimes obscure)
ways that physicists separate uncertainties into ``statistical'' and ``systematic''.
And what's ``systematic'' to some users will be ``statistical'' to others.
We will return to that point below.

One of my grad-school mentors\footnote{Gerry Neugebauer (1932--2014),
  who was one of the pioneers of infrared astrophysics, and the US
  lead of the NASA \textsl{IRAS} Mission, and a wonderful human
  being.} liked to say, when I said something about ``errors'' or
``error bars'', that ``they are \emph{uncertainties} not
\emph{errors}! If they were \emph{errors}, we'd correct them!'' That
phrase rings in my head every day. But this points out a difficulty,
which is in the interpretation of uncertainty estimates. When we say
that some parameter is measured to be $42\pm 6$, what does that ``$\pm 6$''
mean?  The answer depends a bit on your statistical philosophy:
If you are a Bayesian, it means that you believe that, with some
fairly well-defined probability (like maybe 68\,percent), the
parameter is within that range.

Seem straightforward? It is, but the straightforwardness of the Bayesian
comes at a cost, which is in assumptions. If you don't want to make some
of those assumptions, you can be a frequentist instead, but then the
interpretation of the measurement $42\pm 6$ is not so simple! For a frequentist
the meaning is that, if the \emph{true}
value of the parameter were $42$,
in some well defined fraction (like maybe 68\,percent)
of hypothetically repeated experiments with similar-quality data the
best-fit or estimated value of the parameter would be within that range.
That is definitely \emph{not} straightforward.
The Bayesian's answer is about the \emph{parameter}, the frequentist's
answer is about hypothetically repeated \emph{counterfactual experiments}.
The trade-off between assumptions made and
simplicity of interpetation will come up again below.
And, combined with this, there are things to say about the terribly named
``confidence interval'' and the even worse-named ``credible region'' and other
abominations.

Most of you, I hope, don't care about such pedantic details and just
want an \emph{uncertainty estimate on your measurement}. In what follows,
I will try to give you that, with enough discussion to answer questions
and explain your choices. We'll start with the theoretical approaches and
then pivot to the empirical approaches.

\section{Simplest case: the linear least-square fit}

The simplest case for uncertainty estimation---and a case you may have
encountered previously---is a standard, linear fit, as we have
discussed endlessly in this series.\footnote{See, for example, the
  first two \sectionname s of \cite{straightline}. And also the
  applied math in \cite{gaussianproduct}.}  This is the case in which
the following things hold:
\begin{itemize}
\item You have $N$ data points $y_n$. These could be scalars or vectors, but
  let's call them scalars for now.
\item Each data point $y_n$ has an assoicated noise variance
  $\sigma^2_n$, which is the variance of zero-mean Gaussian noise that
  affects each data point $y_n$.  You believe these noise variance
  estimates.\footnote{We will return to the question of testing or
    believing your uncertainties below.}
\item There are no other sources of noise and there is no
  non-Gaussianity (no skewness or kurtosis or outliers or the like) to
  the noise. The noise in data point $y_n$ is independent of the noise
  in any other data point.\footnote{This assumption is the
    easiest---of all these assumptions---to relax.}
\item There is a set of $K$ features $x_{kn}$ for each data point $y_n$ such that
  the expectation for data point $y_n$ is going to be fit as a linear combination
  of these features. That is, the model\footnote{I use the word ``model'' to mean
    a collection of things. It is (at least) a prediction for the data and a
    prediction for the distribution of the noise. A model, for me, is everything
    that you need to construct a likelihood function, or a pdf for the data given
    your parameters.}
  is
  \begin{equation}
    y_n = \sum_{k=1}^K a_k\,x_{kn} + \mbox{noise}
    \quad,
  \end{equation}
  where the noise on data point $y_n$ is drawn, by assumption, from a distribution
  that is Gaussian, zero mean, and variance $\sigma^2_n$.
\end{itemize}
When \emph{all} of these assumptions hold---or, really, when you are
willing to assume \emph{all} of these things---the maximum-likelihood
estimates\footnote{I will distinguish a parameter,
  for example $a_2$, from an \emph{estimate} of that parameter, for example $\hat{a}_2$.
  The estimate is the outcome of applying an estimator to the data.
  The parameter can in principle take on values other than the estimated value; the
  parameter is a variable whereas the estimate is a value for that variable.}
$\hat{a}_k$ for the parameters $a_k$ can be found by minimizing what
physicists call ``chi-squared''\footnote{HOGG: Differences between physicists
  and statisticians here.}
\begin{equation}
  \chi^2 = \sum_{n=1}^N \frac{\left[y_n - \sum_k a_k\,x_{kn}\right]^2}{\sigma^2_n}
\end{equation}
The magic\footnote{This magic is described in much more detail in \cite{straightline}.}
is that the maximum-likelihood parameter estimates
$\hat{a}_k$ are given by straightforward linear algebra:
\begin{equation}\label{eq:llsf}
  \hat{\va} = [\mX\T\cdot\tC\inv\cdot\mX]\inv\cdot\mX\T\cdot\tC\inv\cdot\vy
\end{equation}
\begin{equation}
  \hat{\va}\T \equiv \begin{bmatrix} \hat{a}_1 & \hat{a}_2 & \hdots & \hat{a}_K \end{bmatrix}
\end{equation}
\begin{equation}
  \mX \equiv \begin{bmatrix}
    x_{11} & x_{21} & \hdots & x_{K1} \\
    x_{12} & x_{22} & \hdots & x_{K2} \\
    x_{13} & x_{23} & \hdots & x_{K3} \\
    \vdots & \vdots &        & \vdots \\
    x_{1N} & x_{2N} & \hdots & x_{KN}
    \end{bmatrix}
\end{equation}
\begin{equation}
  \tC\inv \equiv \begin{bmatrix}
    1/\sigma^2_1 & 0 & 0 & \hdots & 0 \\
    0 & 1/\sigma^2_2 & 0 & \hdots & 0 \\
    0 & 0 & 1/\sigma^2_3 & \hdots & 0 \\
    \vdots & \vdots & \vdots & & \vdots \\
    0 & 0 & 0 & \hdots & 1/\sigma^2_N \\
    \end{bmatrix}
\end{equation}
\begin{equation}
  \vy\T \equiv \begin{bmatrix} y_1 & y_2 & y_3 & \hdots & y_N \end{bmatrix}
  \quad ,
\end{equation}
where $\hat{\va}$ is the (column) vector of parameter estimates $\hat{a}_k$,
$\mX$ is the desgin matrix of features $x_{kn}$,
$\tC\inv$ is the inverse variance tensor for the data\footnote{Note about
  typesetting: I typeset vectors---which are all column vectors---like
  $\va$, $\vy$. I typeset arbitrary rectangular matrices like $\mX$
  and variance tensors or information tensors (which must be
  non-negative definite, square martrices) like $\tC$.}
which is diagonal in this simple case),
and
$\vy$ is the (column) vector of data points $y_n$.\footnote{It is beyond the
  scope of this \documentname, but if you are actually implementing the estimator
  of \equationname~(\ref{eq:llsf}), you don't want to naively construct the
  tensor $\tC$ (which is almost entirely zeros). Write your code to just do the
  diagonal multiply directly. Also, you never want to use the inverse function
  \code{inv()}; instead use the \code{solve()} or \code{(lstsq()} function, which
  does the multiply by the inverse more precisely than just naively taking the
  inverse. There are a lot more things to say about implementation that go
  beyond these pieces of advice; I am putting these here just to make the point
  that implementation of the simple formula isn't, itself, necessarily simple.}

When this (\ref{eq:llsf}) is your estimator for $\hat{\va}$, and when
the assumptions (listed above) hold (or you are willing to hold
them\footnote{HOGG polemic here about subjectivity BUT ALSO
  checkability of assumptions.}),
then the formal or standard uncertainty on the $K$-vector of parameter
estimates $\hat{\va}$ is the $K\times K$ uncertainty tensor $\tC_a$
\begin{equation}
  \tC_a = [\mX\T\cdot\tC\inv\cdot\mX]\inv
  \quad.
\end{equation}
How do we interpret this object?

...HOGG interpret this object.

...If you want the uncertainty on JUST ONE component of $\va$, profiling out
the rest or marginalizing out the rest (with a wide prior) then the relevant
uncertainty is the diagonal element of $[\mX\T\cdot\tC\inv\cdot\mX]\inv$. There
is a big difference between the diagonal element of $\tC_a$ and the inverse
of the diagonal element of $\tC_a\inv$.

...HOGG emphasize here strongly that we have now solved the problem good
enough for many users. Only read on if this is \emph{not good enough} for your
needs. It might not be good enough because your fit is nonlinear (ref forward).
It might not be good enough because you don't have a LF (ref forward). It might
not be good enough because you don't trust your uncertainty estimates or your
other assumptions (ref forward).

Perhaps because I am a physicist, I like to think in terms of units and dimensions.
These linear-algebra operators have units, and the result $\hat{\va}$ must have correct
units.
The $N$-vector of data $\vy$ has, say,
``data units'' (maybe photons per second, say, or maybe Kelvins, or maybe
magnitudes or Janskys if you are an astronomer).
Or maybe even each row of $\vy$ has its own special units, if the data are
very heterogeneous.
The inverse variance tensor $\tC\inv$ has inverse-data-squared units, because
it contains inverted, squared uncertainties.
The design matrix $\mX$ has units of ``data per parameter'' because when the
features $x_{kn}$ in the design matrix are multiplied by the parameters $a_k$
in the parameter vector $\va$ they produce predictions for the data.
Again, every row of the parameter vector $\va$ can have different units, but
then every element $x_{kn}$ of the design matrix $\mX$ has units of data element
$y_n$ divided by the units of parameter $a_k$.
With these observations, it is a nice exercise to show that the estimator
$\hat{\va}$ given in \equationname~(\ref{eq:llsf}) has correct parameter
units, and so does the uncertainty tensor $\tC_a$.\footnote{The
  requirement that equations have correct units---that the left-hand
  and right-hand sides of every equation have the same units---is a
  fundamental symmetry of everything in all of science. Yes, I think
  this is a symmetry.}

\section{Generalization to nonlinear models}

If you want to derive the magical linear least-squares estimator above,
or if you want to generalize what we have done to nonlinear models,
it is useful to note that the linear-algebra objects defined
above have the following properties:
The objective function $\chi^2$ can be written as
\begin{equation}
  \chi^2(\va) = [\vy - \mX\cdot\va]\T\cdot\tC\inv\cdot[\vy - \mX\cdot\va]
  \quad,
\end{equation}
where we have written this as a function of the parameter vector $\va$ because
that is the thing with respect to which we minimized to get the estimates
$\hat{\va}$.
The likelihood function---the probability density function (pdf) for
the data given the parameters---can be written as
\begin{equation}
  p(\vy\given\va) = \normal(\vy\given\mX\cdot\va,\tC)
  \quad,
\end{equation}
where $\normal(x\given m,V)$ is the Gaussian pdf given mean $m$ and variance $V$.
The log-likelihood function is
\begin{equation}
  \ln\like(\va) = -\frac{1}{2}\,\chi^2(\va) -\frac{1}{2}\,||2\pi\,\tC||
  \quad,
\end{equation}
where $||V||$ is the determinant operator and we have written the
log-likelihood as a function of the parameters $\va$ even though it is
also a function of the data $\vy$ and the noise variance $\tC$.
We write it as a function only of the parameters because when we manipulate it
(in a moment), we only take derivatives with respect to these parameters.

If we take one derivative of $\ln\like(\va)$ with respect to $\va$ and set it
to zero, we find the optimum given by the magic formula in
\equationname~(\ref{eq:llsf}).
If we take two derivatives of $\ln\like(\va)$ with respect to $\va$ we get
\begin{equation}
  -\frac{\dd^2}{\dd\va^2}\,\ln\like(\va) = \mX\T\cdot\tC\inv\cdot\mX = \tC_a\inv
  \quad.
\end{equation}
That is, the (negative of the) second derivative of the log-likelihood function is
the inverse variance tensor $\tC_a\inv$.
That's important for generalizing the simple, linear case.

...Comment on units and shapes of objects.

...NOTE language that the inverse variance is called the information tensor or the precision matrix or other such things.

...Non-linear fit. What's different?

\section{Information theory}

Connection to Cram\'er--Rao bound and Fisher information.

Relationship of first derivative squared to second derivative.

Note inherent frequentism in this point of view.

\section{Bayes}

Foo

You are only permitted to make one kind of uncertainty estimate in Bayes.

So you better believe that model really really well.

Or make it more baroque. (Good option for a problem / exercise!)

\section{Data simulation}

Hello world.

\section{Jackknife and bootstrap}

Hello world.

\section{Nuisance parameters}

Difference between marginalizing and profiling.

Identicality when it comes to the linear, Gaussian case.

What it looks like.

What it looks like in very nonlinear situations (like period fitting).

\section{Systematic error and theoretical uncertainty}

There is only bias and variance; nothing else.

What is a statistical uncertainty? And what is a systematic one?

When do you want to use the former? When do you want to add both in quadrature?

\section{Visualizing and reporting uncertainties}

\section{Common mistakes and troubleshooting}

About 68\,percent of your values should be outside one sigma. What do think
or do if that's not true?

The uncertainty on the mean vs the distribution of values.

My data aren't well fit by my model; what does that mean for my uncertainty
analysis?

Do I multiply my uncertainties up or do I add something in quadrature?

Do I multiply my uncertainties down?

Sometimes you only need the error bars to be correct in a
\emph{relative} sense. If, say they are just being used to weight (by
their squared inverses) data in a fit.

Sometimes you have huge theoretical uncertainties and you want to use
them in your analysis. Sometimes you have these and you \emph{don't} want
to use them in your analysis.

\section{Discussion}

Hello world.

% Render the references
\clearpage\raggedright
\bibliography{refs}

\end{document}
