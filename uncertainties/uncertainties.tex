% This document is part of the Data Analysis Recipes project.
% Copyright 2020 the author.

% to-do
% -----
% - make up a toy data set and make problems.
%   - make two different generative models for the toy data.

\documentclass[12pt, letterpaper]{article}

\begin{document}

\section*{Data Analysis Recipes:\\
  What is the uncertainty on my measurement?}

\textbf{David W. Hogg} \\
{\footnotesize New York University} \\
{\footnotesize Max-Planck-Institut f\"ur Astronomie} \\
{\footnotesize Flatiron Institute}

\paragraph{Abstract:}
Any measurement you make using data ought to be reported with an uncertainty
estimate (often called an ``error'' or an ``error bar'' unfortunately).
I discuss and compare methodologies for making such estimates.
One important consideration is whether you have a generative model for your
data, with which either you can simulate your noisy data, or (even better)
compute probability densities for different data sets.
Even if you have a generative model, another important consideration is whether
you believe it, or believe what it implies for the moments of
the noise distribution.
If you have a good generative model, information theory or data simulations can deliver
measurement uncertainties.
If you don't, bootstrap and jackknife methods provide well justified, empirical
alternatives.
I also discuss the role of nuisance parameters in uncertainty estimation, and
the differences between Bayesian and frequentist approaches and interpretation.
I spend a bit of time on common issues and troubleshooting.
One important idea is that the circumstances in which an uncertainty can be estimated
precisely are rare: Even when you have a precise measurement, you probably won't know
your uncertainty with similar precision.

\section{Measurements and uncertainties}

Hello world.

Different ways of making a measurement: Bayes, max-like, rando estimator.

Comments on terminology---should this be its own section?

\section{The standard errors on a least-square fit}

Hello world. Linear fit.

Non-linear fit.

\section{Information theory}

Connection to Cram\'er--Rao bound and Fisher information.

\section{Bayes}

Foo

\section{Data simulation}

Hello world.

\section{Jackknife and bootstrap}

Hello world.

\section{Nuisance parameters}

Difference between marginalizing and profiling.

Identicality when it comes to the linear, Gaussian case.

What it looks like.

What it looks like in very nonlinear situations (like period fitting).

\section{Common mistakes and troubleshooting}

About 68\,percent of your values should be outside one sigma. What do think
or do if that's not true?

The uncertainty on the mean vs the distribution of values.

My data aren't well fit by my model; what does that mean for my uncertainty
analysis?

\section{Discussion}

Hello world.

\end{document}
